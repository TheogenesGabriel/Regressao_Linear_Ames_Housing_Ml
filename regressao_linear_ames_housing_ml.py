# -*- coding: utf-8 -*-
"""Regressao_Linear_Ames_Housing_ML.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1hXSR09xmZP50v1prHbcD03Zw-M8NKbb3

# Regressão Linear simples com Scikit-learn no dataset Ames Housing

## 1. Carregando as Bibliotecas e o Dataset
"""

# Importando as Bibliotecas necessárias
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_absolute_error, r2_score

import kagglehub

# Download latest version
path = kagglehub.dataset_download("shashanknecrothapa/ames-housing-dataset")

print("Path to dataset files:", path)

import os
# Importando a base de dados do kaggle
df = pd.read_csv(os.path.join(path, "AmesHousing.csv"))

df.head() # Verificando as 5 primeiras linhas do Dataset

"""## 2. Realizando a EDA (Análise exploratória de Dados)
### Essa etapa é crucial no trabalho de regresão linear porque garante que o modelo seja treinado com dados confiável, além de permitir uma análise prévia dos dados disponível. Dessa maneira, garantindo compreenção e confiança nos dados.
"""

df.info() # tipos dos dados

df.shape # dimensões da Matriz

"""## 3. Limpeza e Tratamento de Valores Ausentes
### Essa etapa garante que a base de dados treine o modelo com valores válidos.
"""

# Identificar colunas com porcentagem de valores ausentes
missing_percentage = df.isnull().sum() / len(df) * 100

# Remover colunas com mais de 50% de valores ausentes
columns_to_drop_simple = missing_percentage[missing_percentage > 50].index.tolist()
df = df.drop(columns=columns_to_drop_simple, errors='ignore')
print(f"Colunas removidas (mais de 50% NaN): {columns_to_drop_simple}")

# Imputar valores numéricos com a mediana
for col in df.select_dtypes(include=['float64', 'int64']).columns:
    if df[col].isnull().any():
        df[col] = df[col].fillna(df[col].median())

# Imputar valores categóricos com a moda
for col in df.select_dtypes(include=['object']).columns:
    if df[col].isnull().any():
        df[col] = df[col].fillna(df[col].mode()[0])

# Verificar se ainda há valores ausentes
remaining_missing = df.isnull().sum()
remaining_missing = remaining_missing[remaining_missing > 0]

if not remaining_missing.empty:
    print("\nValores ausentes restantes após a limpeza inicial:")
    display(remaining_missing)
else:
    print("\nTodos os valores ausentes foram tratados.")

# Verificando novamente o info para confirmar os tipos e ausentes
df.info()

"""## 4. Heatmap para visualiza a correlação das variáveis numéricas
### Mapa de calor no qual é possível verficar as correlações entre variáveis
"""

plt.figure(figsize=(12, 10))
sns.heatmap(df.corr(numeric_only=True), cmap='coolwarm', linewidths=.5)
plt.title('Heatmap de Correlação das Variáveis Numéricas')
plt.show()

"""## 5. Analisando as Correlações, Separando e Treinando o Modelo

### Durante essa etapa, com base no heatmap, foi possível selecionar as variáveis numéricas mais correlacionadas com o preço do imóvel (SalePrice). Em seguida, o conjunto de dados foi dividido em conjunto de treinamento e conjunto de teste. Posteriormente, o modelo foi criado e treinado utilizando a biblioteca Scikit-learn.
"""

# Selecionando as variáveis que estão mais correlacionadas baseadas no heatmap
features = ['Overall Qual', 'Gr Liv Area', 'Year Built', 'Garage Yr Blt', 'Garage Area', 'Garage Cars', 'TotRms AbvGrd']
X = df[features]
y = df['SalePrice']

# Separando o conjunto de treinamento e teste
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Criando o modelo e treinando
modelo = LinearRegression()
modelo.fit(X_train, y_train)

# Predição do modelo
y_pred = modelo.predict(X_test)

"""## 6. Visualização da Regressão: Real vs Previsto

### Esse gráfico simples mostra a relação entre o preço real e o previsto pelo modelo.
"""

plt.figure(figsize=(10, 6))
plt.scatter(y_test, y_pred, alpha=0.5, color='royalblue')
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2, label='Linha de Regressão (Bissetriz)')
plt.legend()
plt.xlabel('Preço Real')
plt.ylabel('Preço Previsto')
plt.title('Regressão Linear: Real vs Previsto')
plt.show()

"""## 7. Visualização da Regressão em relação a magnitude dos erros da Previsão
### Nesse plot é possível visualizar o tamanho do erro, isto é, o valor real subtraído do valor previsto no modelo.


"""

# Calculando o erro absoluto para cada previsão
erros = np.abs(y_test - y_pred)

plt.figure(figsize=(12, 7))

# Criando o scatter plot onde a cor (c) depende do tamanho do erro
scatter = plt.scatter(y_test, y_pred, alpha=0.6, c=erros, cmap='viridis')

# Adicionando a linha de referência (Identidade)
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()],
         linestyle='--', color='red', lw=2, label='Perfeição (Erro Zero)')

# Adicionando uma barra de cores para legenda do erro
cbar = plt.colorbar(scatter)
cbar.set_label('Magnitude do Erro (R$)')

plt.xlabel('Valores Reais (Preço de Venda)')
plt.ylabel('Valores Previstos pelo Modelo')
plt.title('Análise de Resíduos: Quão longe estamos da perfeição?')
plt.legend()
plt.show()